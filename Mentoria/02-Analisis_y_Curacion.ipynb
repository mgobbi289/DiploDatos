{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2021\n",
    "\n",
    "\n",
    "### Categorización de publicaciones de productos realizadas en Mercado Libre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 - Análisis y Curación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones generales que aplican a todos los prácticos:\n",
    "   - Las notebooks tienen que ser 100% reproducibles, es decir al ejecutar las celdas tal cuál como se entrega la notebook se deben obtener los mismos resultados sin errores.\n",
    "   - Código legible, haciendo buen uso de las celdas de la notebook y en lo posible seguir estándares de código para *Python* (https://www.python.org/dev/peps/pep-0008/).\n",
    "   - Utilizar celdas tipo *Markdown* para ir guiando el análisis.\n",
    "   - Limpiar el output de las celdas antes de entregar el notebook (ir a *Kernel* --> *Restart Kernel and Clear All Ouputs*).\n",
    "   - Incluir conclusiones del análisis que se hizo en la sección \"Conclusiones\". Tratar de aportar valor en esta sección, ser creativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección A:  Limpieza de texto / Preprocessing\n",
    "\n",
    "Tener en cuenta lo siguiente: \n",
    "\n",
    "1. *Unidecode*\n",
    "\n",
    "2. Pasar a minúsculas\n",
    "\n",
    "3. Limpiar números\n",
    "\n",
    "4. Limpiar símbolos **(** ' ! ¡ \" @ % & * , . : ; < = > ? @ \\ ^ _ { | } ~ \\t \\n [ ] ` $ **)**\n",
    "\n",
    "5. Limpiar caracteres que suelen usarse como espacios **(** ' + ( ) - \\ **)**\n",
    "\n",
    "6. Reemplazar contracciones, por ejemplo, **c/u** por *cada uno*, **c/** por *con*, **p/** por *para*.\n",
    "\n",
    "7. Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección B: Tokenización & Secuencias\n",
    "\n",
    "1. Utilizar métodos `fit_on_texts()`, `texts_to_sequences()`, y `pad_sequences()`:\n",
    "\n",
    "- https://keras.io/api/preprocessing/text/#tokenizer-class\n",
    "\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección C: Label Encoding\n",
    "\n",
    "1. Utilizar método `LabelEncoder()` de *sklearn*:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección D: Word Embeddings\n",
    "\n",
    "Generar los *word embeddings* correspondientes, de las siguientes dos formas:\n",
    "\n",
    "1. *Custom Word Embeddings*\n",
    "2. *Loading Pretrained Word Embeddings* (**opcional**)\n",
    "\n",
    "En ambos puntos el objetivos final es llegar a crear la *embedding layer* de *keras*:\n",
    "\n",
    "- https://keras.io/api/layers/core_layers/embedding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Código y Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de dataset reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('DataSet/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiamos el dataset brevemente antes de comenzar a operar sobre el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>646019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Teclado Casio Ctk-1300</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>551878</td>\n",
       "      <td>328992</td>\n",
       "      <td>35973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title label_quality    language category\n",
       "count                   646760        646760      646760   646760\n",
       "unique                  646019             2           2       20\n",
       "top     Teclado Casio Ctk-1300    unreliable  portuguese    PANTS\n",
       "freq                         2        551878      328992    35973"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (646760, 4)\n",
      "----------\n",
      "Variables: ['title', 'label_quality', 'language', 'category']\n",
      "----------\n",
      "Categorías: ['BABY_CAR_SEATS', 'BABY_STROLLERS', 'COFFEE_MAKERS', 'ELECTRIC_DRILLS', 'HAIR_CLIPPERS', 'KITCHEN_SINKS', 'MATTRESSES', 'MEMORY_CARDS', 'MOTORCYCLE_JACKETS', 'MUSICAL_KEYBOARDS', 'PANTS', 'PUREBRED_DOGS', 'RANGES', 'REFRIGERATORS', 'ROLLER_SKATES', 'SEWING_MACHINES', 'SHORTS', 'SUITCASES', 'WALL_CLOCKS', 'WINES']\n"
     ]
    }
   ],
   "source": [
    "classes = np.sort(df_dataset.category.unique())\n",
    "\n",
    "print(f'Dimensiones: {df_dataset.shape}')\n",
    "print('----------')\n",
    "print(f'Variables: {list(df_dataset.columns)}')\n",
    "print('----------')\n",
    "print(f'Categorías: {list(classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de aplicar la limpieza, demos un vistazo a algunas de las publicaciones de nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181848</th>\n",
       "      <td>Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478587</th>\n",
       "      <td>Heladera  Saccol  Mod. Hsa32 320 Litros</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606516</th>\n",
       "      <td>Fogão Com Porta Full Glass E Timer E Relógio D...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534521</th>\n",
       "      <td>The Beatles 09 - Relógio Disco De Vinil Decora...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450844</th>\n",
       "      <td>Relógio De Parede Carrilhão Herweg Ref: 5352-084</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352207</th>\n",
       "      <td>Aparadora Acabamento Maquina 100% Original Pan...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>HAIR_CLIPPERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320466</th>\n",
       "      <td>Filhote Spitz Alemão Laranja Com Pedigree Cbkc</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PUREBRED_DOGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517042</th>\n",
       "      <td>Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519168</th>\n",
       "      <td>Teclado Korg Pa 600 Novíssimo Sem Detalhes</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>MUSICAL_KEYBOARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407836</th>\n",
       "      <td>Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>SUITCASES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title label_quality  \\\n",
       "181848  Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...      reliable   \n",
       "478587            Heladera  Saccol  Mod. Hsa32 320 Litros    unreliable   \n",
       "606516  Fogão Com Porta Full Glass E Timer E Relógio D...    unreliable   \n",
       "534521  The Beatles 09 - Relógio Disco De Vinil Decora...    unreliable   \n",
       "450844   Relógio De Parede Carrilhão Herweg Ref: 5352-084      reliable   \n",
       "352207  Aparadora Acabamento Maquina 100% Original Pan...      reliable   \n",
       "320466    Filhote Spitz Alemão Laranja Com Pedigree Cbkc     unreliable   \n",
       "517042  Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...    unreliable   \n",
       "519168         Teclado Korg Pa 600 Novíssimo Sem Detalhes      reliable   \n",
       "407836  Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...    unreliable   \n",
       "\n",
       "          language           category  \n",
       "181848  portuguese             RANGES  \n",
       "478587     spanish      REFRIGERATORS  \n",
       "606516  portuguese             RANGES  \n",
       "534521  portuguese        WALL_CLOCKS  \n",
       "450844  portuguese        WALL_CLOCKS  \n",
       "352207  portuguese      HAIR_CLIPPERS  \n",
       "320466  portuguese      PUREBRED_DOGS  \n",
       "517042     spanish      REFRIGERATORS  \n",
       "519168  portuguese  MUSICAL_KEYBOARDS  \n",
       "407836  portuguese          SUITCASES  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.sample(10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unidecode**\n",
    "\n",
    "A simple vista, se eliminan los tildes (en ambos idiomas).\n",
    "\n",
    "Desde la [documentación](https://pypi.org/project/Unidecode/), se especifica:\n",
    "\n",
    "It often happens that you have text data in *Unicode*, but you need to represent it in *ASCII*.\n",
    "\n",
    "What **Unidecode** provides is a middle road: the function `unidecode()` takes *Unicode* data and tries to represent it in *ASCII* characters (i.e., the universally displayable characters between `0x00` and `0x7F`), where the compromises taken when mapping between two character sets are chosen to be near what a human with a *US* keyboard would choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['clean_title'] = df_dataset.title.apply(unidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minúsculas**\n",
    "\n",
    "Se pasa todo a minúscula (en ambos idiomas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['clean_title'] = df_dataset.clean_title.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpiar Números**\n",
    "\n",
    "Se borran todos los números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['clean_title'] = df_dataset.clean_title.apply(lambda x: re.sub(r'[0-9]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contracciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACA DEBERIAMOS CAMBIAR LAS CONTRACCIONES NO ENCONTRE COMO TODAVIA ASI DESPUES SACAMOS TODOS LOS SIMBOLOS\n",
    "df_dataset['clean_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpiar Símbolos**\n",
    "\n",
    "Se borran todos los símbolos que no sean letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['clean_title'] = df_dataset.clean_title.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza Definitiva**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damos un vistazo al resultado del procesamiento, luego de haber aplicado todos los pasos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181848</th>\n",
       "      <td>Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "      <td>fogao a gas  bocas industrial  innal alta pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478587</th>\n",
       "      <td>Heladera  Saccol  Mod. Hsa32 320 Litros</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "      <td>heladera  saccol  mod  hsa  litros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606516</th>\n",
       "      <td>Fogão Com Porta Full Glass E Timer E Relógio D...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "      <td>fogao com porta full glass e timer e relogio d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534521</th>\n",
       "      <td>The Beatles 09 - Relógio Disco De Vinil Decora...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "      <td>the beatles    relogio disco de vinil decoraca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450844</th>\n",
       "      <td>Relógio De Parede Carrilhão Herweg Ref: 5352-084</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "      <td>relogio de parede carrilhao herweg ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352207</th>\n",
       "      <td>Aparadora Acabamento Maquina 100% Original Pan...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>HAIR_CLIPPERS</td>\n",
       "      <td>aparadora acabamento maquina   original panaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320466</th>\n",
       "      <td>Filhote Spitz Alemão Laranja Com Pedigree Cbkc</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PUREBRED_DOGS</td>\n",
       "      <td>filhote spitz alemao laranja com pedigree cbkc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517042</th>\n",
       "      <td>Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "      <td>heladera siam hsi rt roja  litros retro combi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519168</th>\n",
       "      <td>Teclado Korg Pa 600 Novíssimo Sem Detalhes</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>MUSICAL_KEYBOARDS</td>\n",
       "      <td>teclado korg pa  novissimo sem detalhes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407836</th>\n",
       "      <td>Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>SUITCASES</td>\n",
       "      <td>mala berlim  azul marinho  m   hgm   le postiche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title label_quality  \\\n",
       "181848  Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...      reliable   \n",
       "478587            Heladera  Saccol  Mod. Hsa32 320 Litros    unreliable   \n",
       "606516  Fogão Com Porta Full Glass E Timer E Relógio D...    unreliable   \n",
       "534521  The Beatles 09 - Relógio Disco De Vinil Decora...    unreliable   \n",
       "450844   Relógio De Parede Carrilhão Herweg Ref: 5352-084      reliable   \n",
       "352207  Aparadora Acabamento Maquina 100% Original Pan...      reliable   \n",
       "320466    Filhote Spitz Alemão Laranja Com Pedigree Cbkc     unreliable   \n",
       "517042  Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...    unreliable   \n",
       "519168         Teclado Korg Pa 600 Novíssimo Sem Detalhes      reliable   \n",
       "407836  Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...    unreliable   \n",
       "\n",
       "          language           category  \\\n",
       "181848  portuguese             RANGES   \n",
       "478587     spanish      REFRIGERATORS   \n",
       "606516  portuguese             RANGES   \n",
       "534521  portuguese        WALL_CLOCKS   \n",
       "450844  portuguese        WALL_CLOCKS   \n",
       "352207  portuguese      HAIR_CLIPPERS   \n",
       "320466  portuguese      PUREBRED_DOGS   \n",
       "517042     spanish      REFRIGERATORS   \n",
       "519168  portuguese  MUSICAL_KEYBOARDS   \n",
       "407836  portuguese          SUITCASES   \n",
       "\n",
       "                                              clean_title  \n",
       "181848  fogao a gas  bocas industrial  innal alta pres...  \n",
       "478587                 heladera  saccol  mod  hsa  litros  \n",
       "606516  fogao com porta full glass e timer e relogio d...  \n",
       "534521  the beatles    relogio disco de vinil decoraca...  \n",
       "450844          relogio de parede carrilhao herweg ref     \n",
       "352207  aparadora acabamento maquina   original panaso...  \n",
       "320466    filhote spitz alemao laranja com pedigree cbkc   \n",
       "517042      heladera siam hsi rt roja  litros retro combi  \n",
       "519168            teclado korg pa  novissimo sem detalhes  \n",
       "407836   mala berlim  azul marinho  m   hgm   le postiche  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.sample(10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos nuestro conjunto de datos en los vectores `X`, e `y`.\n",
    "\n",
    "- El primero, `X`, comprende los títulos procesados de las publicaciones.\n",
    "\n",
    "- El segundo, `y`, representa las categorías de las publicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('galoneira semi industrial', 'SEWING_MACHINES')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = df_dataset.clean_title.values\n",
    "y = df_dataset.category.values\n",
    "\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos `Tokenizer()` para convertir los títulos de publicaciones en vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos conocer el tamaño de nuestro vocabulario (se suma `+ 1` para contemplar las palabras *out of vocabulary*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78808"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada palabra se transforma al correspondiente índice en nuestro vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[609, 165, 48]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(X)\n",
    "\n",
    "embedded_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos *padding* para que todos los vectores de palabras tengan tamaños equivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([609, 165,  48,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, padding='post')\n",
    "\n",
    "padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646760, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ammount_sentences, sentences_length = padded_sentences.shape\n",
    "\n",
    "ammount_sentences, sentences_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos codificar las categorías de nuestras publicaciones.\n",
    "Por lo tanto, utilizamos `LabelEncoder()` para transformar los nombres en valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas categorías identificó el *encoder*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BABY_CAR_SEATS', 'BABY_STROLLERS', 'COFFEE_MAKERS',\n",
       "       'ELECTRIC_DRILLS', 'HAIR_CLIPPERS', 'KITCHEN_SINKS', 'MATTRESSES',\n",
       "       'MEMORY_CARDS', 'MOTORCYCLE_JACKETS', 'MUSICAL_KEYBOARDS', 'PANTS',\n",
       "       'PUREBRED_DOGS', 'RANGES', 'REFRIGERATORS', 'ROLLER_SKATES',\n",
       "       'SEWING_MACHINES', 'SHORTS', 'SUITCASES', 'WALL_CLOCKS', 'WINES'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la transformación aprendida a todas las categorías de nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, solo restan obtener los *word embeddings* para los títulos de nuestras publicaciones.\n",
    "Utilizaremos `Embedding()` para calcularlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Word Embeddings**\n",
    "\n",
    "De manera arbitraria, los vectores resultantes serán de **25** dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embedding_layer = Embedding(vocab_length, 25, input_length=sentences_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretrained Word Embeddings**\n",
    "\n",
    "Desde https://nlp.stanford.edu/projects/glove/, se descarga el *word embeding* entrenado **glove.6B.zip**.\n",
    "\n",
    "De manera arbitraria, utilizaremos los vectores de **100** dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "glove_path = f'DataSet/glove.6B/glove.6B.{embedding_dim}d.txt'\n",
    "glove_file = open(glove_path, encoding=\"utf8\")\n",
    "\n",
    "# Prepare embedding dictionary\n",
    "embeddings_dictionary = dict()\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 28673 words (50134 misses)\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f'Converted {hits} words ({misses} misses)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embedding_layer = Embedding(vocab_length,\n",
    "                                    embedding_dim,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=sentences_length,\n",
    "                                    trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para practicar un poco con nuestra implementación, intentamos predecir con lo que tenemos hasta este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 22, 25)            1970200   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 551       \n",
      "=================================================================\n",
      "Total params: 1,970,751\n",
      "Trainable params: 1,970,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20212/20212 [==============================] - 820s 40ms/step - loss: 0.0000e+00 - acc: 0.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e5c5e3520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ya que este proceso puede demorar, realizaremos un entrenamiento breve\n",
    "model.fit(padded_sentences, encoded_labels, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.847702383995056\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos contra nuestro propio conjunto de entrenamiento\n",
    "loss, accuracy = model.evaluate(padded_sentences, encoded_labels, verbose=0)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Material de ayuda para el desarrollo de este práctico:\n",
    "\n",
    "1. Implementación en *keras* de *word embeddings*: https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras\n",
    "2. Como utilizar *pre-trained word embeddings* en *keras*: https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "3. *Word Embeddings*: https://jalammar.github.io/illustrated-word2vec/\n",
    "3. Curso de **procesamiento del lenguaje natural** con *keras*: https://www.coursera.org/learn/natural-language-processing-tensorflow/home/welcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
