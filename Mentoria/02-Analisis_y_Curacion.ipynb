{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2021\n",
    "\n",
    "\n",
    "### Categorización de publicaciones de productos realizadas en Mercado Libre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 - Análisis y Curación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones generales que aplican a todos los prácticos:\n",
    "   - Las notebooks tienen que ser 100% reproducibles, es decir al ejecutar las celdas tal cuál como se entrega la notebook se deben obtener los mismos resultados sin errores.\n",
    "   - Código legible, haciendo buen uso de las celdas de la notebook y en lo posible seguir estándares de código para *Python* (https://www.python.org/dev/peps/pep-0008/).\n",
    "   - Utilizar celdas tipo *Markdown* para ir guiando el análisis.\n",
    "   - Limpiar el output de las celdas antes de entregar el notebook (ir a *Kernel* --> *Restart Kernel and Clear All Ouputs*).\n",
    "   - Incluir conclusiones del análisis que se hizo en la sección \"Conclusiones\". Tratar de aportar valor en esta sección, ser creativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección A:  Limpieza de texto / Preprocessing\n",
    "\n",
    "Tener en cuenta lo siguiente: \n",
    "\n",
    "1. *Unidecode*\n",
    "\n",
    "2. Pasar a minúsculas\n",
    "\n",
    "3. Limpiar números\n",
    "\n",
    "4. Limpiar símbolos **(** ' ! ¡ \" @ % & * , . : ; < = > ¿ ? @ \\ ^ _ { | } ~ \\t \\n [ ] ` $ **)**\n",
    "\n",
    "5. Limpiar caracteres que suelen usarse como espacios **(** ' + ( ) - \\ **)**\n",
    "\n",
    "6. Reemplazar contracciones, por ejemplo, **c/u** por *cada uno*, **c/** por *con*, **p/** por *para*.\n",
    "\n",
    "7. Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección B: Tokenización & Secuencias\n",
    "\n",
    "1. Utilizar métodos `fit_on_texts()`, `texts_to_sequences()`, y `pad_sequences()`:\n",
    "\n",
    "- https://keras.io/api/preprocessing/text/#tokenizer-class\n",
    "\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección C: Label Encoding\n",
    "\n",
    "1. Utilizar método `LabelEncoder()` de *sklearn*:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección D: Word Embeddings\n",
    "\n",
    "Generar los *word embeddings* correspondientes, de las siguientes dos formas:\n",
    "\n",
    "1. *Custom Word Embeddings*\n",
    "2. *Loading Pretrained Word Embeddings* (**opcional**)\n",
    "\n",
    "En ambos puntos el objetivos final es llegar a crear la *embedding layer* de *keras*:\n",
    "\n",
    "- https://keras.io/api/layers/core_layers/embedding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Código y Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de dataset reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('DataSet/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiamos el dataset brevemente antes de comenzar a operar sobre el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "      <td>646760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>646019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Achaval Ferrer Malbec 2015</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>551878</td>\n",
       "      <td>328992</td>\n",
       "      <td>35973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title label_quality    language category\n",
       "count                       646760        646760      646760   646760\n",
       "unique                      646019             2           2       20\n",
       "top     Achaval Ferrer Malbec 2015    unreliable  portuguese    PANTS\n",
       "freq                             2        551878      328992    35973"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (646760, 4)\n",
      "----------\n",
      "Variables: ['title', 'label_quality', 'language', 'category']\n",
      "----------\n",
      "Categorías: ['BABY_CAR_SEATS', 'BABY_STROLLERS', 'COFFEE_MAKERS', 'ELECTRIC_DRILLS', 'HAIR_CLIPPERS', 'KITCHEN_SINKS', 'MATTRESSES', 'MEMORY_CARDS', 'MOTORCYCLE_JACKETS', 'MUSICAL_KEYBOARDS', 'PANTS', 'PUREBRED_DOGS', 'RANGES', 'REFRIGERATORS', 'ROLLER_SKATES', 'SEWING_MACHINES', 'SHORTS', 'SUITCASES', 'WALL_CLOCKS', 'WINES']\n"
     ]
    }
   ],
   "source": [
    "classes = np.sort(df_dataset.category.unique())\n",
    "\n",
    "print(f'Dimensiones: {df_dataset.shape}')\n",
    "print('----------')\n",
    "print(f'Variables: {list(df_dataset.columns)}')\n",
    "print('----------')\n",
    "print(f'Categorías: {list(classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de aplicar la limpieza, demos un vistazo a algunas de las publicaciones de nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181848</th>\n",
       "      <td>Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478587</th>\n",
       "      <td>Heladera  Saccol  Mod. Hsa32 320 Litros</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606516</th>\n",
       "      <td>Fogão Com Porta Full Glass E Timer E Relógio D...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534521</th>\n",
       "      <td>The Beatles 09 - Relógio Disco De Vinil Decora...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450844</th>\n",
       "      <td>Relógio De Parede Carrilhão Herweg Ref: 5352-084</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352207</th>\n",
       "      <td>Aparadora Acabamento Maquina 100% Original Pan...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>HAIR_CLIPPERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320466</th>\n",
       "      <td>Filhote Spitz Alemão Laranja Com Pedigree Cbkc</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PUREBRED_DOGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517042</th>\n",
       "      <td>Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519168</th>\n",
       "      <td>Teclado Korg Pa 600 Novíssimo Sem Detalhes</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>MUSICAL_KEYBOARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407836</th>\n",
       "      <td>Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>SUITCASES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title label_quality  \\\n",
       "181848  Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...      reliable   \n",
       "478587            Heladera  Saccol  Mod. Hsa32 320 Litros    unreliable   \n",
       "606516  Fogão Com Porta Full Glass E Timer E Relógio D...    unreliable   \n",
       "534521  The Beatles 09 - Relógio Disco De Vinil Decora...    unreliable   \n",
       "450844   Relógio De Parede Carrilhão Herweg Ref: 5352-084      reliable   \n",
       "352207  Aparadora Acabamento Maquina 100% Original Pan...      reliable   \n",
       "320466    Filhote Spitz Alemão Laranja Com Pedigree Cbkc     unreliable   \n",
       "517042  Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...    unreliable   \n",
       "519168         Teclado Korg Pa 600 Novíssimo Sem Detalhes      reliable   \n",
       "407836  Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...    unreliable   \n",
       "\n",
       "          language           category  \n",
       "181848  portuguese             RANGES  \n",
       "478587     spanish      REFRIGERATORS  \n",
       "606516  portuguese             RANGES  \n",
       "534521  portuguese        WALL_CLOCKS  \n",
       "450844  portuguese        WALL_CLOCKS  \n",
       "352207  portuguese      HAIR_CLIPPERS  \n",
       "320466  portuguese      PUREBRED_DOGS  \n",
       "517042     spanish      REFRIGERATORS  \n",
       "519168  portuguese  MUSICAL_KEYBOARDS  \n",
       "407836  portuguese          SUITCASES  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.sample(10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicamos Limpieza**\n",
    "\n",
    "Se define la serie de operaciones para la limpieza de títulos de publicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(title):\n",
    "    \"\"\"\n",
    "    Aplica las operaciones de limpieza a un título de una publicación.\n",
    "    \"\"\"\n",
    "    # Unidecode: Convierte string de Unicode a ASCII.\n",
    "    title = unidecode(title)\n",
    "    # Pasamos a Minúsculas.\n",
    "    title = title.lower()\n",
    "    # Eliminamos Números.\n",
    "    title = re.sub(r'[0-9]+', '', title)\n",
    "    # Reemplazamos Contracciones.\n",
    "    title = re.sub(r'c/u', 'cada uno', title)\n",
    "    title = re.sub(r'c/', 'con', title)\n",
    "    title = re.sub(r'p/', 'para', title)\n",
    "    # Limpiamos Símbolos.\n",
    "    title = re.sub('[^a-zA-Z ]', '', title)\n",
    "    # Retornamos el título de la publicación procesado.\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['clean_title'] = df_dataset.title.apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza Definitiva**\n",
    "\n",
    "Damos un vistazo al resultado del procesamiento, luego de haber aplicado todos los pasos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181848</th>\n",
       "      <td>Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "      <td>fogao a gas  bocas industrial  innal alta pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478587</th>\n",
       "      <td>Heladera  Saccol  Mod. Hsa32 320 Litros</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "      <td>heladera  saccol  mod hsa  litros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606516</th>\n",
       "      <td>Fogão Com Porta Full Glass E Timer E Relógio D...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>RANGES</td>\n",
       "      <td>fogao com porta full glass e timer e relogio d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534521</th>\n",
       "      <td>The Beatles 09 - Relógio Disco De Vinil Decora...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "      <td>the beatles   relogio disco de vinil decoracao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450844</th>\n",
       "      <td>Relógio De Parede Carrilhão Herweg Ref: 5352-084</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "      <td>relogio de parede carrilhao herweg ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352207</th>\n",
       "      <td>Aparadora Acabamento Maquina 100% Original Pan...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>HAIR_CLIPPERS</td>\n",
       "      <td>aparadora acabamento maquina  original panason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320466</th>\n",
       "      <td>Filhote Spitz Alemão Laranja Com Pedigree Cbkc</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>PUREBRED_DOGS</td>\n",
       "      <td>filhote spitz alemao laranja com pedigree cbkc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517042</th>\n",
       "      <td>Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>REFRIGERATORS</td>\n",
       "      <td>heladera siam hsirt roja  litros retro combi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519168</th>\n",
       "      <td>Teclado Korg Pa 600 Novíssimo Sem Detalhes</td>\n",
       "      <td>reliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>MUSICAL_KEYBOARDS</td>\n",
       "      <td>teclado korg pa  novissimo sem detalhes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407836</th>\n",
       "      <td>Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>SUITCASES</td>\n",
       "      <td>mala berlim azul marinho m  hgm  le postiche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title label_quality  \\\n",
       "181848  Fogão A Gás 4 Bocas Industrial  Innal Alta Pre...      reliable   \n",
       "478587            Heladera  Saccol  Mod. Hsa32 320 Litros    unreliable   \n",
       "606516  Fogão Com Porta Full Glass E Timer E Relógio D...    unreliable   \n",
       "534521  The Beatles 09 - Relógio Disco De Vinil Decora...    unreliable   \n",
       "450844   Relógio De Parede Carrilhão Herweg Ref: 5352-084      reliable   \n",
       "352207  Aparadora Acabamento Maquina 100% Original Pan...      reliable   \n",
       "320466    Filhote Spitz Alemão Laranja Com Pedigree Cbkc     unreliable   \n",
       "517042  Heladera Siam Hsi-rt60 Roja 420 Litros Retro C...    unreliable   \n",
       "519168         Teclado Korg Pa 600 Novíssimo Sem Detalhes      reliable   \n",
       "407836  Mala Berlim, Azul Marinho, M - Hg703m - Le Pos...    unreliable   \n",
       "\n",
       "          language           category  \\\n",
       "181848  portuguese             RANGES   \n",
       "478587     spanish      REFRIGERATORS   \n",
       "606516  portuguese             RANGES   \n",
       "534521  portuguese        WALL_CLOCKS   \n",
       "450844  portuguese        WALL_CLOCKS   \n",
       "352207  portuguese      HAIR_CLIPPERS   \n",
       "320466  portuguese      PUREBRED_DOGS   \n",
       "517042     spanish      REFRIGERATORS   \n",
       "519168  portuguese  MUSICAL_KEYBOARDS   \n",
       "407836  portuguese          SUITCASES   \n",
       "\n",
       "                                              clean_title  \n",
       "181848  fogao a gas  bocas industrial  innal alta pres...  \n",
       "478587                  heladera  saccol  mod hsa  litros  \n",
       "606516  fogao com porta full glass e timer e relogio d...  \n",
       "534521  the beatles   relogio disco de vinil decoracao...  \n",
       "450844            relogio de parede carrilhao herweg ref   \n",
       "352207  aparadora acabamento maquina  original panason...  \n",
       "320466    filhote spitz alemao laranja com pedigree cbkc   \n",
       "517042       heladera siam hsirt roja  litros retro combi  \n",
       "519168            teclado korg pa  novissimo sem detalhes  \n",
       "407836       mala berlim azul marinho m  hgm  le postiche  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.sample(10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación sobre Unidecode**\n",
    "\n",
    "A simple vista, se eliminan los tildes (en ambos idiomas).\n",
    "\n",
    "Desde la [documentación](https://pypi.org/project/Unidecode/), se especifica:\n",
    "\n",
    "It often happens that you have text data in *Unicode*, but you need to represent it in *ASCII*.\n",
    "\n",
    "What **Unidecode** provides is a middle road: the function `unidecode()` takes *Unicode* data and tries to represent it in *ASCII* characters (i.e., the universally displayable characters between `0x00` and `0x7F`), where the compromises taken when mapping between two character sets are chosen to be near what a human with a *US* keyboard would choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos nuestro conjunto de datos en los vectores `X`, e `y`.\n",
    "\n",
    "- El primero, `X`, comprende los títulos procesados de las publicaciones.\n",
    "\n",
    "- El segundo, `y`, representa las categorías de las publicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('galoneira semi industrial', 'SEWING_MACHINES')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = df_dataset.clean_title.values\n",
    "y = df_dataset.category.values\n",
    "\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos `Tokenizer()` para convertir los títulos de publicaciones en vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos conocer el tamaño de nuestro vocabulario (se suma `+ 1` para contemplar las palabras *out of vocabulary*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97180"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada palabra se transforma al correspondiente índice en nuestro vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[613, 201, 47]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(X)\n",
    "\n",
    "embedded_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos *padding* para que todos los vectores de palabras tengan tamaños equivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([613, 201,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, padding='post')\n",
    "\n",
    "padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646760, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ammount_sentences, sentences_length = padded_sentences.shape\n",
    "\n",
    "ammount_sentences, sentences_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos codificar las categorías de nuestras publicaciones.\n",
    "Por lo tanto, utilizamos `LabelEncoder()` para transformar los nombres en valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas categorías identificó el *encoder*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BABY_CAR_SEATS', 'BABY_STROLLERS', 'COFFEE_MAKERS',\n",
       "       'ELECTRIC_DRILLS', 'HAIR_CLIPPERS', 'KITCHEN_SINKS', 'MATTRESSES',\n",
       "       'MEMORY_CARDS', 'MOTORCYCLE_JACKETS', 'MUSICAL_KEYBOARDS', 'PANTS',\n",
       "       'PUREBRED_DOGS', 'RANGES', 'REFRIGERATORS', 'ROLLER_SKATES',\n",
       "       'SEWING_MACHINES', 'SHORTS', 'SUITCASES', 'WALL_CLOCKS', 'WINES'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la transformación aprendida a todas las categorías de nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, solo restan obtener los *word embeddings* para los títulos de nuestras publicaciones.\n",
    "Utilizaremos `Embedding()` para calcularlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Word Embeddings**\n",
    "\n",
    "De manera arbitraria, los vectores resultantes serán de **25** dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embedding_layer = Embedding(vocab_length, 25, input_length=sentences_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretrained Word Embeddings**\n",
    "\n",
    "Desde https://nlp.stanford.edu/projects/glove/, se descarga el *word embeding* entrenado **glove.6B.zip**.\n",
    "\n",
    "De manera arbitraria, utilizaremos los vectores de **100** dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "glove_path = f'DataSet/glove.6B/glove.6B.{embedding_dim}d.txt'\n",
    "glove_file = open(glove_path, encoding=\"utf8\")\n",
    "\n",
    "# Prepare embedding dictionary\n",
    "embeddings_dictionary = dict()\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 28573 words (68606 misses)\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f'Converted {hits} words ({misses} misses)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embedding_layer = Embedding(vocab_length,\n",
    "                                    embedding_dim,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=sentences_length,\n",
    "                                    trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el laboratorio, nos concentramos principalmente en la curación de títulos de publicaciones en nuestro conjunto de datos, preparando la información para el aprendizaje de un futuro modelo.\n",
    "Por lo tanto, no contamos con demasiadas conclusiones sobre el procesamiento realizado.\n",
    "De todas formas, a continuación listaremos algunas observaciones interesantes.\n",
    "\n",
    "- La limpieza de títulos resulta una tarea compleja, y podría ser necesario regresar a esta etapa para refinarla.\n",
    "- El tamaño de nuestro vocabulario es **97180**. Hay que tener en cuenta que estamos trabajando con dos idiomas al mismo tiempo. Quizás podría ser necesario reducir su tamaño, limitándonos a las palabras más comunes.\n",
    "- Algunos parámetros fueron definidos de manera totalmente arbitraria, como las dimensiones de nuestro *word embedding* (**25**), o las dimensiones de los *word vectors* preentrenados (**100**).\n",
    "- Se utilizan los [GloVe](https://nlp.stanford.edu/projects/glove/) como nuestros *word vectors* preentrenados. Hay que notar que los vectores están preparados para trabajar con documentos en inglés (razón por cual convertimos solo **28573** palabras, y perdemos **68606**). Una alternativa, sería utilizar [fastText](https://fasttext.cc/docs/en/pretrained-vectors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje Automático..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para practicar un poco con nuestra implementación, intentaremos predecir con lo que tenemos hasta este punto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(trained_embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(classes), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 22, 100)           9718000   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                44020     \n",
      "=================================================================\n",
      "Total params: 9,762,020\n",
      "Trainable params: 44,020\n",
      "Non-trainable params: 9,718,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitaríamos un paso adicional de procesamiento para utilizar nuestras categorías en el modelo definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_labels = to_categorical(encoded_labels, num_classes=len(classes))\n",
    "\n",
    "encoded_labels[0], one_hot_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiendo del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20212/20212 [==============================] - 268s 13ms/step - loss: 0.9694 - acc: 0.7447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f5c3a7610>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ya que este proceso puede demorar, realizaremos un entrenamiento breve\n",
    "model.fit(padded_sentences, one_hot_labels, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.84065318107605\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos contra nuestro propio conjunto de entrenamiento\n",
    "loss, accuracy = model.evaluate(padded_sentences, one_hot_labels, verbose=0)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicción**\n",
    "\n",
    "Se define un conjunto de datos de test improvisado, para analizar si el modelo aprende como nosotros esperamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(\n",
    "    [\n",
    "        'silla bebe auto',\n",
    "        'maquina cafe taza',\n",
    "        'cama dormir colchon',\n",
    "        'musica teclado teclas',\n",
    "        'jean pantalon talle',\n",
    "        'perro golden macho',\n",
    "        'heladera freezer frio',\n",
    "        'vino estancia uva'\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_test = np.array(\n",
    "    [\n",
    "        'BABY_CAR_SEATS',\n",
    "        'COFFEE_MAKERS',\n",
    "        'MATTRESSES',\n",
    "        'MUSICAL_KEYBOARDS',\n",
    "        'PANTS',\n",
    "        'PUREBRED_DOGS',\n",
    "        'REFRIGERATORS',\n",
    "        'WINES'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos aplicar el mismo procesamiento del conjunto de entrenamiento, al conjunto improvisado de test (los títulos de las publicaciones no necesitan ser curados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([237, 7, 39],\n",
       " array([237,   7,  39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences_test = word_tokenizer.texts_to_sequences(X_test)\n",
    "padded_sentences_test = pad_sequences(embedded_sentences_test, sentences_length, padding='post')\n",
    "\n",
    "embedded_sentences_test[0], padded_sentences_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels_test = le.transform(y_test)\n",
    "one_hot_labels_test = to_categorical(encoded_labels_test, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2,  0,  2, 10, 11, 13, 19]),\n",
       " array([ 0,  2,  6,  9, 10, 11, 13, 19]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intentamos predecir los datos improvisados\n",
    "predictions = model.predict(padded_sentences_test, verbose=0)\n",
    "\n",
    "np.argmax(predictions, axis=-1), encoded_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvo las publicaciones de `MATTRESSES` y `MUSICAL_KEYBOARDS`, nuestro modelos predijo correctamente los datos de juguete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Material de ayuda para el desarrollo de este práctico:\n",
    "\n",
    "1. Implementación en *keras* de *word embeddings*: https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras\n",
    "2. Como utilizar *pre-trained word embeddings* en *keras*: https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "3. *Word Embeddings*: https://jalammar.github.io/illustrated-word2vec/\n",
    "3. Curso de **procesamiento del lenguaje natural** con *keras*: https://www.coursera.org/learn/natural-language-processing-tensorflow/home/welcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
