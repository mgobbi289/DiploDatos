{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2021\n",
    "\n",
    "\n",
    "### Categorización de publicaciones de productos realizadas en Mercado Libre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 - Análisis y Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones generales que aplican a todos los prácticos:\n",
    "   - Las notebooks tienen que ser 100% reproducibles, es decir al ejecutar las celdas tal cuál como se entrega la notebook se deben obtener los mismos resultados sin errores.\n",
    "   - Código legible, haciendo buen uso de las celdas de la notebook y en lo posible seguir estándares de código para *Python* (https://www.python.org/dev/peps/pep-0008/).\n",
    "   - Utilizar celdas tipo *Markdown* para ir guiando el análisis.\n",
    "   - Limpiar el output de las celdas antes de entregar el notebook (ir a *Kernel* **-->** *Restart Kernel and Clear All Ouputs*).\n",
    "   - Incluir conclusiones del análisis que se hizo en la sección \"Conclusiones\". Tratar de aportar valor en esta sección, ser creativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección A:  Estadísticas básicas & Visualizaciones\n",
    "\n",
    "Por cada uno de los siguientes puntos realizar un análisis para poder responder el enunciado/pregunta y generar alguna gráfica para visualizar los resultados:\n",
    "\n",
    "1. ¿Cuántas publicaciones de items hay dentro de cada categoría?\n",
    "2. Proporción de publicaciones en español y portugués dentro de cada categoría.\n",
    "3. Proporción de label quality dentro de cada categoría.\n",
    "4. Relación entre el label quality y el idioma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección B: Estadísticas de las publicaciones & Visualizaciones\n",
    "\n",
    "Por cada uno de los siguientes puntos realizar un análisis para poder responder el enunciado/pregunta y generar alguna gráfica para visualizar los resultados:\n",
    "\n",
    "1. Cantidad promedio de palabras del título de la publicacion por categoría.\n",
    "2. Análisis general de *stopwords*, números, caracteres especiales, etc.. Puede ser un recuento promedio por publicación, no es necesario realizar una gráfica en este punto.\n",
    "3. Palabras más frecuentes dentro de cada categoría (sin incluir *stopwords*, números, caracteres especiales, etc.).\n",
    "\n",
    "Tener en cuenta librerías como *NLTK* y *spaCy* para el procesamiento de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Código y Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# Make sure it's 4.14.3\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de dataset reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('DataSet/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiamos el dataset brevemente antes de comenzar a operar sobre el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dimensiones: {df_dataset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Variables: {list(df_dataset.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Etiquetas: {list(df_dataset.label_quality.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Lenguajes: {list(df_dataset.language.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Categorías: {list(df_dataset.category.unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 646760 productos en nuestro dataframe, con las variables\n",
    "- `title` la mayoría de los títulos son únicos\n",
    "- `label_quality` solo se separan en *unreliable* y *reliable*\n",
    "- `language` solo se separan en *portuguese* y *spanish*\n",
    "- `category` hay un total de veinte categorías diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Contamos la cantidad de publicaciones por categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count = df_dataset.category\\\n",
    "    .value_counts()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index': 'category', 'category': 'count'})\n",
    "\n",
    "category_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de publicaciones por categoría\n",
    "sns.catplot(x='count', y='category', data=category_count, kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "- La categoría `PANTS` es la más común (35973 publicaciones).\n",
    "- La categoría `WALL_CLOCKS` es la menos común (30600 publicaciones).\n",
    "\n",
    "Podíamos decir que las categorías están bastante balancedas, teniendo en cuenta que la mayor diferencia entre la cantidad de publicaciones por categoría es cercana a 5000.\n",
    "Obviamente, esto es consecuencia de haber tomar las 20 categorías más repetidas en el dataset original de **ML**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Proporción de publicaciones en español y portugués dentro de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las columnas relevantes\n",
    "relevant_cols = ['category', 'language']\n",
    "\n",
    "# Agregamos según el lenguaje\n",
    "category_language_count = df_dataset\\\n",
    "    .groupby(relevant_cols)\\\n",
    "    .agg(language_count=('language', 'count'))\\\n",
    "    .reset_index()\n",
    "\n",
    "# Cantidad de publicaciones en español y en portugués dentro de cada categoría\n",
    "sns.catplot(x='language_count',\n",
    "            y='category',\n",
    "            hue ='language',\n",
    "            data=category_language_count,\n",
    "            kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar nos permite obtener la proporción (en lugar de la cantidad)\n",
    "category_language_count = pd.crosstab(index=df_dataset['category'],\n",
    "                                      columns=df_dataset['language'],\n",
    "                                      normalize='index',\n",
    "                                      margins=True)\n",
    "\n",
    "category_language_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la proporción de publicaciones en cada idioma, por categoría\n",
    "category_language_count.plot.barh(stacked=True,\n",
    "                                  figsize=(14, 8),\n",
    "                                  title='Proporción de lenguajes por categoría');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "- La cantidad de publicaciones en cada idioma es similar.\n",
    "    - Portugués **50.9%**\n",
    "    - Español **49.1%**\n",
    "\n",
    "- Hay **12** categorías con mayor cantidad de publicaciones en portugués.\n",
    "  Por lo tanto, hay **8** categorías con mayor cantidad de publicaciones en español.\n",
    "\n",
    "- La categoría con mayor proporción de portugués es `MEMORY_CARDS` con **57.8%**.\n",
    "- La categoría con mayor proporción de español es `REFRIGERATORS` con **54.8%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Proporción de etiquetas dentro de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las columnas relevantes\n",
    "relevant_cols = ['category', 'label_quality']\n",
    "\n",
    "# Agregamos según la etiqueta\n",
    "category_quality_count = df_dataset\\\n",
    "    .groupby(relevant_cols)\\\n",
    "    .agg(quality_count=('label_quality', 'count'))\\\n",
    "    .reset_index()\n",
    "\n",
    "# Cantidad de etiquetas dentro de cada categoría\n",
    "sns.catplot(x='quality_count',\n",
    "            y='category',\n",
    "            hue ='label_quality',\n",
    "            data=category_quality_count,\n",
    "            kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar nos permite obtener la proporción (en lugar de la cantidad)\n",
    "category_quality_count = pd.crosstab(index=df_dataset['category'],\n",
    "                                     columns=df_dataset['label_quality'],\n",
    "                                     normalize='index',\n",
    "                                     margins=True)\n",
    "\n",
    "category_quality_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la proporción de etiquetas, por categoría\n",
    "category_quality_count.plot.barh(stacked=True,\n",
    "                                 figsize=(14, 8),\n",
    "                                 title='Proporción de etiquetas por categoría');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "- La cantidad de publicaciones con cada etiqueta es notoriamente diferente.\n",
    "    - Confiable **14.7%**\n",
    "    - No Confiable **85.3%**\n",
    "\n",
    "- Ninguna categoría tiene una mayor cantidad de publicaciones verificadas, que no verificadas.\n",
    "\n",
    "- La categoría con mayor proporción de publicaciones verificadas es `PANTS` con **22.3%**.\n",
    "- La categoría con mayor proporción de publicaciones no verificadas es `WINES` con **97.1%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Relación entre la etiqueta y el lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las columnas relevantes\n",
    "relevant_cols = ['category', 'language', 'label_quality']\n",
    "\n",
    "# Agregamos según la categoría\n",
    "category_language_quality_count = df_dataset\\\n",
    "    .groupby(relevant_cols)\\\n",
    "    .agg(language_quality_count=('category', 'count'))\\\n",
    "    .reset_index()\n",
    "\n",
    "# Cantidad de lenguajes / etiquetas dentro de cada categoría\n",
    "sns.catplot(x='language_quality_count',\n",
    "            y='category',\n",
    "            hue='label_quality',\n",
    "            col='language',\n",
    "            data=category_language_quality_count,\n",
    "            kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar nos permite obtener la proporción (en lugar de la cantidad)\n",
    "language_quality_count = pd.crosstab(index=df_dataset['language'],\n",
    "                                     columns=df_dataset['label_quality'],\n",
    "                                     normalize=True,\n",
    "                                     margins=True)\n",
    "\n",
    "language_quality_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la proporción de etiquetas y de lenguajes\n",
    "plot_df = language_quality_count.drop(index='All').drop(columns='All')\n",
    "\n",
    "plot_df.plot.barh(stacked=True,\n",
    "                  figsize=(14, 8),\n",
    "                  title='Proporción de etiquetas y de lenguajes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "Si se toma un publicación cualquiera del dataset, lo más probable es obtener una publicación en portugués no verificada (**43.1%**), mientras que lo menos probable es obtener una publicación en español verificada (**6.9%**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiamos el dataset original\n",
    "df_nlp = df_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos modelos específicos para cada uno de los lenguajes.\n",
    "\n",
    "- **Español** `es_core_news_sm`\n",
    "- **Portugués** `pt_core_news_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\"\"\"\n",
    "Una optimización posible sería cargar solamente los componentes\n",
    "que vamos a utilizar, es decir, el tokenizer y el tagger.\n",
    "\"\"\"\n",
    "\n",
    "# Modelo para procesar Español\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "# Modelo para procesar Portugués\n",
    "nlp_pt = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_lang = {'spanish': nlp_es, 'portuguese': nlp_pt}\n",
    "\n",
    "def tokenizer(row):\n",
    "    \"\"\"\n",
    "    Dada una fila del dataset, aplica el procesamiento al título:\n",
    "    - Tokenizer: separa en tokens\n",
    "    - Tagger: agrega información sintáctica/semántica\n",
    "    Es importante procesar de acuerdo al lenguaje de la publicación.\n",
    "    \"\"\"\n",
    "    nlp = nlp_lang[row.language]\n",
    "    # Por cuestiones de eficiencia, solo aplicamos estas etapas.\n",
    "    return nlp.tagger(nlp.tokenizer(row.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos algo manejable para realizar el análisis...\n",
    "df_nlp = df_nlp.sample(50000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['tokens'] = df_nlp.apply(tokenizer, axis=1)\n",
    "\n",
    "df_nlp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Cantidad promedio de palabras en el título de la publicación por categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1: Contar la cantidad de tokens.\n",
    "df_ammount_tokens = df_nlp.copy()\n",
    "\n",
    "df_ammount_tokens['ammount_tokens'] = df_ammount_tokens.tokens.apply(lambda tokens: len(tokens))\n",
    "\n",
    "df_ammount_tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['category', 'ammount_tokens']\n",
    "\n",
    "df_ammount_tokens = df_ammount_tokens[relevant_cols]\\\n",
    "    .groupby('category')\\\n",
    "    .agg(ammount_tokens_mean=('ammount_tokens', 'mean'))\\\n",
    "    .reset_index()\n",
    "\n",
    "df_ammount_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de la cantidad de tokens por categoría\n",
    "sns.catplot(x='ammount_tokens_mean',\n",
    "            y='category',\n",
    "            data=df_ammount_tokens,\n",
    "            kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "La categoría con mayor cantidad promedio de tokens en su título es `MEMORY_CARDS` con **10.74**, seguida por `KITCHEN_SINKS` con **9.26**.\n",
    "\n",
    "La categoría con menor cantidad promedio de tokens en su título es `PUREBRED_DOGS` con **5.98**, seguida por `REFRIGERATORS` con **6.91**.\n",
    "\n",
    "El resto de las categorías poseen, en promedio, entre 7 a 8 palabras en su título."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Análisis general de *stopwords*, números, caracteres especiales, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Word**\n",
    "\n",
    "En computación, **stop words** son palabras que serán filtradas durante el *procesamiento del lenguaje natural* de los datos.\n",
    "Normalmente refieren a las palabras más comúnes de un lenguaje, donde no existe una lista absoluta definitiva que contenga a todas las **stop words** de un lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_POS(token):\n",
    "    \"\"\"\n",
    "    Determina si el token corresponde a alguna de las POS:\n",
    "    - ENUM: Números\n",
    "    - PUNCT: Puntuaciones\n",
    "    - SYM: Símbolos\n",
    "    - SPACE: Espacios\n",
    "    \"\"\"\n",
    "    return token.pos_ in ['ENUM', 'PUNCT', 'SYM', 'SPACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2: Contar la cantidad de stop words y otras POS.\n",
    "df_ammount_stop_words = df_nlp.copy()\n",
    "\n",
    "count_stop_words = lambda tokens: sum(map(lambda t: t.is_stop, tokens))\n",
    "count_others_POS = lambda tokens: sum(map(lambda t: other_POS(t), tokens))\n",
    "\n",
    "df_ammount_stop_words['ammount_stop_words'] = df_ammount_stop_words.tokens.apply(count_stop_words)\n",
    "df_ammount_stop_words['ammount_others_POS'] = df_ammount_stop_words.tokens.apply(count_others_POS)\n",
    "\n",
    "df_ammount_stop_words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['category', 'ammount_stop_words', 'ammount_others_POS']\n",
    "\n",
    "df_ammount_stop_words = df_ammount_stop_words[relevant_cols]\\\n",
    "    .groupby('category')\\\n",
    "    .agg(ammount_stop_words_mean=('ammount_stop_words', 'mean'),\n",
    "         ammount_others_POS_mean=('ammount_others_POS', 'mean')\n",
    "        )\\\n",
    "    .reset_index()\n",
    "\n",
    "df_ammount_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de cantidad de stop words (y otras POS) por categoría\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 14), sharex=True, sharey=True)\n",
    "\n",
    "# Stop Words\n",
    "sns.barplot(x='ammount_stop_words_mean',\n",
    "            y='category',\n",
    "            data=df_ammount_stop_words,\n",
    "            ax=axes[0]);\n",
    "\n",
    "# Otras POS\n",
    "sns.barplot(x='ammount_others_POS_mean',\n",
    "            y='category',\n",
    "            data=df_ammount_stop_words,\n",
    "            ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "Es evidente que es más común la ocurrencia de *stop words* en el título de alguna publicación, que el uso de otras *POS* (**Part Of Speech**), al menos en la mayoría de las categorías.\n",
    "\n",
    "La categoría con mayor cantidad promedio de *stop words* en su título es `WALL_CLOCKS` con **1.27**.\n",
    "\n",
    "La categoría con menor cantidad promedio de *stop words* en su título es `MOTORCYCLE_JACKETS` con **0.30**.\n",
    "\n",
    "La categoría con mayor cantidad promedio de otras *POS* en su título es `WINES` con **0.74**.\n",
    "\n",
    "La categoría con menor cantidad promedio de otras *POS* en su título es `KITCHEN_SINKS` con **0.36**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Palabras más frecuentes dentro de cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_word(token):\n",
    "    \"\"\"\n",
    "    Determina si un token corresponde a una palabra válida.\n",
    "    Es decir, no es alguna de las otras POS (ENUM, PUNCT,\n",
    "    SYM, SPACE), ni tampoco una stop word.\n",
    "    \"\"\"\n",
    "    return not (token.is_stop or other_POS(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3: Encontrar las palabras más repetidas.\n",
    "from collections import Counter\n",
    "\n",
    "df_ammount_words = df_nlp.copy()\n",
    "\n",
    "count_words = lambda tokens: Counter([t.text for t in tokens if valid_word(t)])\n",
    "\n",
    "df_ammount_words['ammount_words'] = df_ammount_words.tokens.apply(count_words)\n",
    "\n",
    "df_ammount_words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_counter_sum(series):\n",
    "    \"\"\"\n",
    "    Cada publicación tendrá un conteo de las palabras utilizadas en su título.\n",
    "    Agrupando por categoría, sumamos los contadores de cada publicación.\n",
    "    \"\"\"\n",
    "    return sum(series, Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['category', 'ammount_words']\n",
    "\n",
    "df_ammount_words = df_ammount_words[relevant_cols]\\\n",
    "    .groupby('category')\\\n",
    "    .agg(ammount_words_counter=('ammount_words', agg_counter_sum))\\\n",
    "    .reset_index()\n",
    "\n",
    "df_ammount_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con las 'top_words' de cada categoría.\n",
    "top_words = 3\n",
    "\n",
    "top_words_df = df_ammount_words.copy()\n",
    "\n",
    "top_words_df['ammount_words_counter'] = top_words_df['ammount_words_counter']\\\n",
    "    .apply(lambda c: c.most_common(top_words))\n",
    "\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para un gráfico de barras, deberíamos acomodar nuestro df\n",
    "list_df = []\n",
    "for index, row in top_words_df.iterrows():\n",
    "    for word, count in row.ammount_words_counter:\n",
    "        list_df.append((row.category, word, count))\n",
    "\n",
    "plot_df = pd.DataFrame(list_df, columns=['category', 'word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(plot_df,\n",
    "       x='word',\n",
    "       y='count',\n",
    "       color='category',\n",
    "       width=1500,\n",
    "       height=600,\n",
    "       barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "La mayoría de las palabras más comunes resultan lógicas al ver los resultados obtenidos.\n",
    "\n",
    "La palabra más repetida es **Teclado** con 1853, en la categoría `MUSICAL_KEYBOARDS`.\n",
    "\n",
    "Hay curiosidades como...\n",
    "\n",
    "- La palabra **Maquina** es top tanto para la categoría `HAIR_CLIPPERS` con 692, como en `SEWING_MACHING` con 925.\n",
    "\n",
    "- Palabras top para referirse al mismo elemento, en cada uno de los idiomas.\n",
    "  Por ejemplo, en `REFRIGERATORS` tenemos **Heladera** con 1266 y **Geladeira** con 572.\n",
    "\n",
    "- Los errores de ortografía también son relevantes.\n",
    "  Por ejemplo, en `MATTRESSES` tenemos **Colchon** con 722 y **Colchón** con 498.\n",
    "\n",
    "- Una palabra puede aparecer en singular o en plural.\n",
    "  Por ejemplo, en `PUREBRED_DOGS` tenemos **Filhotes** con 437 y **Filhote** con 304."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las conclusiones particulares de cada ejercicio se fueron anotando al final de cada uno.\n",
    "\n",
    "Como conclusión general, podemos decir que estamos frente a un problema de clasificación complejo, principalmente por la naturaleza del *lenguaje natural*.\n",
    "Además se suma la dificultad de trabajar con dos idiomas al mismo tiempo, español y portugués.\n",
    "\n",
    "El análisis nos aportó una percepción más completa del dataset, y nos ayudó a comenzar a incorporar algunos conceptos básicos de **NLP**.\n",
    "En particular, la librería **spaCy** para *Python*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
