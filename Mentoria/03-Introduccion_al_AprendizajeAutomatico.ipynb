{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2021\n",
    "\n",
    "\n",
    "### Categorización de publicaciones de productos realizadas en Mercado Libre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 - Introducción al Aprendizaje Automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones generales que aplican a todos los prácticos:\n",
    "   - Las notebooks tienen que ser 100% reproducibles, es decir al ejecutar las celdas tal cuál como se entrega la notebook se deben obtener los mismos resultados sin errores.\n",
    "   - Código legible, haciendo buen uso de las celdas de la notebook y en lo posible seguir estándares de código para Python (https://www.python.org/dev/peps/pep-0008/).\n",
    "   - Utilizar celdas tipo \"Markdown\" para ir guiando el análisis.\n",
    "   - Limpiar el output de las celdas antes de entregar el notebook (ir a Kernel --> Restart Kernel and Clear All Ouputs).\n",
    "   - Incluir conclusiones del análisis que se hizo en la sección \"Conclusiones\". Tratar de aportar valor en esta sección, ser creativo! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcional: entregar la solución en scripts de Python. Se lo puede separar al proyecto en *data.py*, *models.py*, *metrics.py*, *train.py*, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 0: Splitteo en train / test set\n",
    "\n",
    "- Splittear en entrenamiento (80%) y test (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 1:\n",
    "\n",
    "Tomamos lo generado en el TP anterior, por lo tanto partir de la ya hecho para tener:\n",
    "\n",
    "- Sequences\n",
    "\n",
    "- Labels\n",
    "\n",
    "- Capa de Embedding\n",
    "\n",
    "(Tener en cuenta que la tokenización se hace por separado en los conjuntos de entrenamiento y test, para evitar leakage de datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2: Splitteo en train / validation set\n",
    "\n",
    "- Splittear al conjunto de entrenamiento en train y validation utilizando el método de Stratified K-Folds cross validation:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 3: Entrenamiento de un modelo\n",
    "\n",
    "- Relizar el entrenamiento de un modelo.\n",
    "\n",
    "- Se aconseja comenzar por una red neuronal feed foward, y/o capas del tipo *LSTM*.\n",
    "\n",
    "- La primera capa de la red será la *embedding_layer* que ya hayan definido y la última capa será una capa densa con cantidad de neuronas = cantidad de clases y función de activación *softmax*.\n",
    "\n",
    "- Entrenar modelos que utilicen tanto los embeddings pre-entrenados como los customs.\n",
    "\n",
    "- Experimentar utilizando dropout y batch normalization.\n",
    "\n",
    "- Utilizar *checkpoints* para guardar el modelo.\n",
    "\n",
    "- Utilizar como *loss* la *'sparse_categorical_crossentropy'*, y se recomienda utilizar *Adam* como *optimizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 4: Evaluación del modelo\n",
    "\n",
    "- Gráficar curvas de loss y accuracy para train y validation set (se puede hacer utilizando el model history de keras: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History).\n",
    "\n",
    "- Utilizar balance accuracy para medir la performance del modelo en validaiton y test: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html\n",
    "\n",
    "- Diferenciar el score según *label_quality*. Es decir, calcular el score para el set de validation y test separando según *reliable* y *unreliable*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 5: Análisis de resultados\n",
    "\n",
    "- Realizar análisis de que modelo performó mejor, generar un csv con los resultados en validation y test de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 6: Exportado de predicciones\n",
    "\n",
    "- Generar un dataframe con las predicciones del conjunto de test del mejor modelo y exportarlo a un *csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Código y análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de dataset reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
