{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2021\n",
    "\n",
    "\n",
    "### Categorización de publicaciones de productos realizadas en Mercado Libre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones generales que aplican a todos los prácticos:\n",
    "\n",
    "- Las notebooks tienen que ser 100% reproducibles, es decir al ejecutar las celdas tal cuál como se entrega la notebook se deben obtener los mismos resultados sin errores.\n",
    "- Código legible, haciendo buen uso de las celdas de la notebook y en lo posible seguir estándares de código para *Python* (https://www.python.org/dev/peps/pep-0008/).\n",
    "- Utilizar celdas tipo *Markdown* para ir guiando el análisis.\n",
    "- Limpiar el output de las celdas antes de entregar el notebook (ir a `Kernel` --> `Restart Kernel and Clear All Ouputs`).\n",
    "- Incluir conclusiones del análisis que se hizo en la sección \"Conclusiones\". Tratar de aportar valor en esta sección, ser creativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consignas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este **TP** es iterar sobre el modelado, experimentando con distintas técnicas, y utilizar el *pipeline* de datos que se realizó en el **TP** pasado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 1: Modelado\n",
    "\n",
    "- Implementar redes del tipo *feed foward* y *LSTM*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 2: Regularización\n",
    "\n",
    "El objetivo de este bloque es experimentar con distintos métodos de regularización.\n",
    "A continuación se deja una lista de distinas técnicas.\n",
    "Investigar de qué se trata cada una e implementarlas.\n",
    "Tener en cuenta que no es necesario implementar todo lo que se propone.\n",
    "\n",
    "- Experimentar con distintos tamaños de modelo. Sacar / agregar capas como así también neuronas.\n",
    "\n",
    "- Utilizar distinos valores de *batch size*.\n",
    "\n",
    "- Experimentar utilizando *dropout* y *batch normalization*. (**HECHO**)\n",
    "\n",
    "- Experimentar con distintos valores para el *learning rate*.\n",
    "\n",
    "- Experimentar con técnicas de *weight decay* y *early stopping*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 3: Ajuste de Hiperparámetros\n",
    "\n",
    "Este bloque es **opcional**, ya que puede ser complejo hacer la implementación en redes neuronales.\n",
    "\n",
    "- Investigar, y en lo posible implemementar, alguna técnica de búsqueda de hiperparámetros como *Grid Search* y *Random Search*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 4: Documentación de Resultados\n",
    "\n",
    "- Dejar documentado de algún lado (puede ser en un documento de texto aparte) los resultados de toda la experimentación de este **TP**. Es importante que queden claros los resultados de las métricas de cada modelo, cual de todos los modelos entrenados fue el superador, y una breve descripción del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Código y análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalaciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de dataset reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('DataSet/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiamos el dataset brevemente antes de comenzar a operar sobre el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.sort(df_dataset.category.unique())\n",
    "\n",
    "print(f'Dimensiones: {df_dataset.shape}')\n",
    "print('----------')\n",
    "print(f'Variables: {list(df_dataset.columns)}')\n",
    "print('----------')\n",
    "print(f'Categorías: {list(classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sección 0:**\n",
    "Preparando el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import cleaning\n",
    "\n",
    "df_dataset['clean_title'] = df_dataset.title.apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_dataset, train_size=0.8, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Dimensiones Entrenamiento: {df_train.shape}')\n",
    "print(f'Dimensiones Evaluación: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de Entrenamiento\n",
    "X_train = df_train.clean_title.values\n",
    "y_train = df_train.category.values\n",
    "# Datos de Test\n",
    "X_test = df_test.clean_title.values\n",
    "y_test = df_test.category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "word_tokenizer = Tokenizer()\n",
    "# Aprendemos el Tokenizer en base a los datos de entrenamiento.\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "# Longitud del Vocabulario en base a los datos de entrenamiento.\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "embedded_sentences_train = word_tokenizer.texts_to_sequences(X_train)\n",
    "embedded_sentences_test = word_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "padded_sentences_train = pad_sequences(embedded_sentences_train, padding='post')\n",
    "# Longitud de Sentencias en base a los datos de entrenamiento.\n",
    "ammount_sentences, sentences_length = padded_sentences_train.shape\n",
    "\n",
    "padded_sentences_test = pad_sequences(embedded_sentences_test, padding='post', maxlen=sentences_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(classes)\n",
    "\n",
    "encoded_labels_train = le.transform(y_train)\n",
    "encoded_labels_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "dense_vector_size = 30\n",
    "embedding_layer = Embedding(vocab_length, dense_vector_size, input_length=sentences_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación**\n",
    "\n",
    "Solo trabajaremos con *custom embeddings* por dificultades encontradas al adaptar el modelo a los *word vectors* preentrenados de **fastText**.\n",
    "Una tarea que quedará pendiente, será replantear el uso de esta herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sección 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models import ...\n",
    "\n",
    "# TODO: Definir que modelos queremos utilizar...\n",
    "\n",
    "models = {m1.name: m1.model, m2.name: m2.model, m3.name: m3.model}\n",
    "weights = {m1.name: m1.filepath, m2.name: m2.filepath, m3.name: m3.filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "Presentar los modelos utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sección 2**\n",
    "\n",
    "En base a la lista de técnicas que tenemos disponible, realizamos una breve investigación de cada una antes de comenzar con su implementación.\n",
    "A continuación mencionamos algunas de sus características relevantes.\n",
    "\n",
    "**Experimentar con los tamaños del modelo**\n",
    "\n",
    "La idea es modificar la arquitectura de la red.\n",
    "Nuestro modelo `Baseline`, por dar un ejemplo, tiene **2** capas ocultas densas, con **256** y **128** neuronas respectivamente.\n",
    "Es una arquitectura definida totalmente de manera arbitraria, y sin ningún fundamento para respaldarla.\n",
    "Durante la experimentación podríamos modificar la cantidad de capas ocultas y/o la cantidad de neuronas en cada una.\n",
    "Quizás reduciendo alguna de estas cantidades podríamos regularizar el aprendizaje y evitar el *overfitting* observado en el **TP** anterior.\n",
    "\n",
    "**Distinos valores de *batch size***\n",
    "\n",
    "El *batch size* determina la cantidad de muestras que serán propagadas por la red (en una iteración de *forward pass* y *backward pass*).\n",
    "Utilizar un tamaño **pequeño** reduce el uso de memoria, y generalmente acelera el entrenamiento al actualizar los pesos luego de cada propagación.\n",
    "Utilizar un tamaño **grande** mejora la precisión de la estimación del gradiente, al observar una mayor cantidad de datos de entrenamiento se puede realizar una actualización más certera de los pesos de la red.\n",
    "\n",
    "**Utilizar *dropout* y *batch normalization***\n",
    "\n",
    "**Dropout** es una técnica donde ciertas neuronas seleccionadas aleatoriamente son ignoradas durante el entrenamiento.\n",
    "Lo cual significa que no contribuirán en la activación de neuronas durante el *forward pass*, y no se le aplicará ninguna actualización de pesos durante el *backward pass*.\n",
    "El objetivo es que la red sea menos sensible a los pesos específicos de las neuronas, y que sea capaz de generalizar mejor.\n",
    "\n",
    "**Batch Normalization** es una capa para normalizar la muestra que recibe.\n",
    "Aplica una transformación que mantiene la *media* cercana a **0**, y su *desviación estándar* cercana a **1**.\n",
    "El objetivo es evitar que ciertas características de los datos dominen el entrenamiento de la red neuronal por sobre las demás.\n",
    "\n",
    "**Distintos valores de *learning rate***\n",
    "\n",
    "Una red neuronal es entrenada utilizando el algoritmo de optimización **Descenso de Gradiente Estocástico** (*SGD*).\n",
    "El *learning rate* es el hiperparámetro que controla cuanto cambiará el modelo en respuesta al error estimado cada vez que los pesos de la red son actualizados.\n",
    "Una tasa de aprendizaje **pequeña** podría resultar en un entrenamiento largo, el cual puede no converger.\n",
    "Una tasa de aprendizaje **grande** podría aprender un conjunto de pesos subóptimos, con un entrenamiento inestable.\n",
    "\n",
    "**Utilizar *weight decay* y *early stopping***\n",
    "\n",
    "**Weight Decay** es una técnica de regularización utilizada en redes neuronales.\n",
    "La idea consiste en agregar un término a la pérdida, el cual sea proporcional a la magnitud de los pesos de la red.\n",
    "De esta manera, durante el proceso de entrenamiento, se intentaría decrementar el valor de los pesos.\n",
    "\n",
    "**Early Stopping** es un método que permite detener el entrenamiento una vez que la red neuronal deja de mejorar su rendimiento.\n",
    "El problema que se intenta solucionar es la elección del número de épocas de entrenamiento.\n",
    "Una cantidad de *epochs* demasiado **grande** puede producir *overfitting*.\n",
    "Una cantidad de *epochs* demasiado **pequeña** puede producir *underfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import ...\n",
    "\n",
    "# TODO: Quizás sea necesario un entrenamiento más refinado...\n",
    "\n",
    "training = {}\n",
    "for name, model in models.items():\n",
    "  print(f'{name}:')\n",
    "  history = train(name, model, padded_sentences_train, encoded_labels_train)\n",
    "  training[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.metrics import plot_accuracy_loss\n",
    "\n",
    "for name, train in training.items():\n",
    "  plot_accuracy_loss(train, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.metrics import show_balanced_accuracy\n",
    "\n",
    "for name, model in models.items():\n",
    "  show_balanced_accuracy(name, model, padded_sentences_test, encoded_labels_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for name, model in models.items():\n",
    "  loss, accuracy = model.evaluate(padded_sentences_test, encoded_labels_test, verbose=0)\n",
    "  data.append({'Model Name': name, 'Test Loss': loss, 'Test Accuracy': accuracy})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Checkpoint/model_results.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = # TODO: Elegir el modelo según los resultados observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "probabilities = chosen_model.predict(padded_sentences_test, verbose=0)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "print(classification_report(encoded_labels_test, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = df_test.title\n",
    "test_prediction = le.inverse_transform(predictions)\n",
    "\n",
    "submission = pd.DataFrame(list(zip(test_title, test_prediction)), columns=['title', 'category'])\n",
    "submission.to_csv('DataSet/dataset_submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sección 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sección 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
